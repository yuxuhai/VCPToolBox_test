// EmbeddingUtils.js
const { get_encoding } = require("@dqbd/tiktoken");
const encoding = get_encoding("cl100k_base");

// é…ç½®
const embeddingMaxToken = parseInt(process.env.WhitelistEmbeddingModelMaxToken, 10) || 8000;
const safeMaxTokens = Math.floor(embeddingMaxToken * 0.85);
const MAX_BATCH_ITEMS = 100; // Gemini/OpenAI é™åˆ¶
const DEFAULT_CONCURRENCY = parseInt(process.env.TAG_VECTORIZE_CONCURRENCY) || 5; // ğŸŒŸ è¯»å–å¹¶å‘é…ç½®

/**
 * å†…éƒ¨å‡½æ•°ï¼šå‘é€å•ä¸ªæ‰¹æ¬¡
 */
async function _sendBatch(batchTexts, config, batchNumber) {
    const { default: fetch } = await import('node-fetch');
    const retryAttempts = 3;
    const baseDelay = 1000;

    for (let attempt = 1; attempt <= retryAttempts; attempt++) {
        try {
            const requestUrl = `${config.apiUrl}/v1/embeddings`;
            const requestBody = { model: config.model, input: batchTexts };
            const requestHeaders = { 'Content-Type': 'application/json', 'Authorization': `Bearer ${config.apiKey}` };

            const response = await fetch(requestUrl, {
                method: 'POST',
                headers: requestHeaders,
                body: JSON.stringify(requestBody)
            });

            const responseBodyText = await response.text();

            if (!response.ok) {
                if (response.status === 429) {
                    // 429 é™æµæ—¶ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                    const waitTime = 5000 * attempt; 
                    console.warn(`[Embedding] Batch ${batchNumber} rate limited (429). Retrying in ${waitTime/1000}s...`);
                    await new Promise(r => setTimeout(r, waitTime));
                    continue;
                }
                throw new Error(`API Error ${response.status}: ${responseBodyText}`);
            }

            const data = JSON.parse(responseBodyText);
            if (!data.data || !Array.isArray(data.data)) {
                throw new Error('Invalid API response structure');
            }
            
            // ç®€å•çš„ Logï¼Œè¯æ˜å¹¶å‘æ­£åœ¨è·‘
            // console.log(`[Embedding] âœ… Batch ${batchNumber} completed (${batchTexts.length} items).`);
            
            return data.data.sort((a, b) => a.index - b.index).map(item => item.embedding);

        } catch (e) {
            console.warn(`[Embedding] Batch ${batchNumber}, Attempt ${attempt} failed: ${e.message}`);
            if (attempt === retryAttempts) throw e;
            await new Promise(r => setTimeout(r, baseDelay * Math.pow(2, attempt)));
        }
    }
}

/**
 * ğŸš€ ç»ˆæç‰ˆï¼šå¹¶å‘æ‰¹é‡è·å– Embeddings
 */
async function getEmbeddingsBatch(texts, config) {
    if (!texts || texts.length === 0) return [];

    // 1. âš¡ï¸ ç¬¬ä¸€æ­¥ï¼šçº¯ CPU æ“ä½œï¼Œå…ˆæŠŠæ‰€æœ‰æ–‡æœ¬åˆ‡åˆ†æˆ Batches
    const batches = [];
    let currentBatch = [];
    let currentBatchTokens = 0;

    for (const text of texts) {
        const textTokens = encoding.encode(text).length;
        if (textTokens > safeMaxTokens) continue; // Skip oversize

        const isTokenFull = currentBatch.length > 0 && (currentBatchTokens + textTokens > safeMaxTokens);
        const isItemFull = currentBatch.length >= MAX_BATCH_ITEMS;

        if (isTokenFull || isItemFull) {
            batches.push(currentBatch);
            currentBatch = [text];
            currentBatchTokens = textTokens;
        } else {
            currentBatch.push(text);
            currentBatchTokens += textTokens;
        }
    }
    if (currentBatch.length > 0) batches.push(currentBatch);

    console.log(`[Embedding] Prepared ${batches.length} batches. Executing with concurrency: ${DEFAULT_CONCURRENCY}...`);

    // 2. ğŸŒŠ ç¬¬äºŒæ­¥ï¼šå¹¶å‘æ‰§è¡Œå™¨
    const results = new Array(batches.length); // é¢„åˆ†é…ç»“æœæ•°ç»„ï¼Œä¿è¯é¡ºåº
    let cursor = 0; // å½“å‰å¤„ç†åˆ°çš„æ‰¹æ¬¡ç´¢å¼•

    // å®šä¹‰ Workerï¼šåªè¦é˜Ÿåˆ—é‡Œè¿˜æœ‰ä»»åŠ¡ï¼Œå°±ä¸æ–­æŠ¢ä»»åŠ¡åš
    const worker = async (workerId) => {
        while (true) {
            // ğŸ”’ è·å–ä»»åŠ¡ç´¢å¼• (åŸå­æ“ä½œæ¨¡æ‹Ÿ)
            const batchIndex = cursor++; 
            if (batchIndex >= batches.length) break; // æ²¡ä»»åŠ¡äº†ï¼Œä¸‹ç­

            const batchTexts = batches[batchIndex];
            // æ‰§è¡Œè¯·æ±‚ (Batch ID ä» 1 å¼€å§‹æ˜¾ç¤º)
            results[batchIndex] = await _sendBatch(batchTexts, config, batchIndex + 1);
        }
    };

    // å¯åŠ¨ N ä¸ª Worker
    const workers = [];
    for (let i = 0; i < DEFAULT_CONCURRENCY; i++) {
        workers.push(worker(i));
    }

    // ç­‰å¾…æ‰€æœ‰ Worker ä¸‹ç­
    await Promise.all(workers);

    // 3. ğŸ“¦ ç¬¬ä¸‰æ­¥ï¼šå±•å¹³ç»“æœ
    // results æ•°ç»„é‡Œå¯èƒ½åŒ…å« undefined (å¦‚æœæŸä¸ª batch æœ€ç»ˆå¤±è´¥)ï¼Œfilter æ‰ä¿å¹³å®‰
    return results.filter(r => r).flat();
}

module.exports = { getEmbeddingsBatch };